{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import MNIST_database as mnist\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "#Choose the final size of your image dataset\n",
    "size_final = 8\n",
    "\n",
    "# data_zoom = mnist.MNISTData(size_initial=20, size_final=size_final, color_depth=5, flat=True)\n",
    "data_zoom = mnist.MNISTData(size_initial=20, size_final=8, color_depth=8, flat=True)\n",
    "\n",
    "x_train= data_zoom.x_train\n",
    "y_train= data_zoom.y_train\n",
    "x_test= data_zoom.x_test\n",
    "y_test= data_zoom.y_test\n",
    "\n",
    "# ax = plt.subplot(1, 1 , 1)\n",
    "# plt.imshow(data_zoom.x_train[0].reshape(size_final,size_final), cmap='gray_r')\n",
    "# ax.get_xaxis().set_visible(False)\n",
    "# ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'default_8bit_quantize_layout_transformer' from 'tensorflow_model_optimization.python.core.quantization.keras.default_8bit' (C:\\Users\\luisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_model_optimization\\python\\core\\quantization\\keras\\default_8bit\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 66\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[39mreturn\u001b[39;00m {}\n\u001b[0;32m     65\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_model_optimization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquantization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdefault_8bit\u001b[39;00m \u001b[39mimport\u001b[39;00m default_8bit_quantize_registry\n\u001b[1;32m---> 66\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtensorflow_model_optimization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpython\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mquantization\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdefault_8bit\u001b[39;00m \u001b[39mimport\u001b[39;00m default_8bit_quantize_layout_transformer\n\u001b[0;32m     69\u001b[0m \u001b[39m# Apply quantization-aware training\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mCustomObjectScope(\n\u001b[0;32m     71\u001b[0m     {\u001b[39m'\u001b[39m\u001b[39mCustomQuantizeConfig\u001b[39m\u001b[39m'\u001b[39m: CustomQuantizeConfig}\n\u001b[0;32m     72\u001b[0m ):\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'default_8bit_quantize_layout_transformer' from 'tensorflow_model_optimization.python.core.quantization.keras.default_8bit' (C:\\Users\\luisa\\AppData\\Roaming\\Python\\Python39\\site-packages\\tensorflow_model_optimization\\python\\core\\quantization\\keras\\default_8bit\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow_model_optimization.python.core.quantization.keras.quantize import quantize_apply, quantize_annotate_layer\n",
    "from tensorflow_model_optimization.python.core.quantization.keras.quantize_config import QuantizeConfig\n",
    "from tensorflow_model_optimization.python.core.quantization.keras.quantize_scheme import QuantizeScheme\n",
    "from tensorflow_model_optimization.python.core.quantization.keras.quantizers import LastValueQuantizer\n",
    "\n",
    "# Set the random seed for reproducibility\n",
    "tf.random.set_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Replace these with your own dataset\n",
    "x_train = np.random.rand(1000, 64)\n",
    "y_train = np.random.rand(1000, 32)\n",
    "\n",
    "BIT_WIDTH = 8\n",
    "input_shape = (x_train.shape[-1],)\n",
    "\n",
    "def create_encoder_decoder_model(input_shape):\n",
    "    inputs = Input(input_shape)\n",
    "    x = quantize_annotate_layer(Dense(64, activation='relu'))(inputs)\n",
    "    x = quantize_annotate_layer(Dense(32, activation='relu'))(x)\n",
    "    x = quantize_annotate_layer(Dense(16, activation='relu'))(x)\n",
    "    x = quantize_annotate_layer(Dense(2, activation='relu'))(x)\n",
    "    x = quantize_annotate_layer(Dense(16, activation='relu'))(x)\n",
    "    x = quantize_annotate_layer(Dense(32, activation='relu'))(x)\n",
    "    outputs = quantize_annotate_layer(Dense(32, activation='linear'))(x)\n",
    "    return Model(inputs, outputs)\n",
    "\n",
    "model = create_encoder_decoder_model(input_shape)\n",
    "\n",
    "class CustomQuantizeConfig(QuantizeConfig):\n",
    "    def __init__(self, custom_quantize_config):\n",
    "        self._quantize_config = custom_quantize_config\n",
    "\n",
    "    def get_quantize_config(self, layer):\n",
    "        return self._quantize_config\n",
    "    \n",
    "    def get_layout_transformer(self):\n",
    "        return default_8bit_quantize_layout_transformer.Default8BitQuantizeLayoutTransformer()\n",
    "    \n",
    "    def get_quantize_registry(self):\n",
    "        return default_8bit_quantize_registry.Default8BitQuantizeRegistry()\n",
    "    def get_weights_and_quantizers(self, layer):\n",
    "        return [(layer.kernel, LastValueQuantizer(num_bits=BIT_WIDTH, symmetric=True, narrow_range=False, per_axis=False))]\n",
    "\n",
    "    def get_activations_and_quantizers(self, layer):\n",
    "        return [(layer.activation, LastValueQuantizer(num_bits=BIT_WIDTH, symmetric=True, narrow_range=False, per_axis=False))]\n",
    "\n",
    "    def set_quantize_weights(self, layer, quantize_weights):\n",
    "        # Add this line for TensorFlow 2.6+\n",
    "        layer.kernel = quantize_weights[0]\n",
    "\n",
    "    def set_quantize_activations(self, layer, quantize_activations):\n",
    "        layer.activation = quantize_activations[0]\n",
    "\n",
    "    def get_output_quantizers(self, layer):\n",
    "        return [LastValueQuantizer(num_bits=BIT_WIDTH, symmetric=True, narrow_range=False, per_axis=False)]\n",
    "\n",
    "    def get_config(self):\n",
    "        return {}\n",
    "\n",
    "from tensorflow_model_optimization.python.core.quantization.keras.default_8bit import default_8bit_quantize_registry\n",
    "from tensorflow_model_optimization.python.core.quantization.keras.default_8bit import default_8bit_quantize_layout_transformer\n",
    "\n",
    "\n",
    "class CustomQuantizeScheme(QuantizeScheme):\n",
    "    \n",
    "# Apply quantization-aware training\n",
    "with tf.keras.utils.CustomObjectScope(\n",
    "    {'CustomQuantizeConfig': CustomQuantizeConfig}\n",
    "):\n",
    "    q_aware_model = quantize_apply(model, CustomQuantizeScheme(CustomQuantizeConfig()))\n",
    "\n",
    "q_aware_model.compile(optimizer='adam', loss='mse')\n",
    "q_aware_model.summary()\n",
    "\n",
    "# Train the model\n",
    "q_aware_model.fit(x_train, y_train, batch_size=32, epochs=20, verbose=1)\n",
    "\n",
    "# Save and load the quantized model\n",
    "q_aware_model.save('q_aware_model.h5')\n",
    "with tf.keras.utils.CustomObjectScope(\n",
    "    {'CustomQuantizeConfig': CustomQuantizeConfig}\n",
    "):\n",
    "    loaded_q_aware_model = load_model('q_aware_model.h5')\n",
    "\n",
    "# Make predictions using the quantized model\n",
    "predictions = loaded_q_aware_model.predict(x_train)\n",
    "\n",
    "# Plot the first 5 predictions\n",
    "for i in range(5):\n",
    "    plt.figure()\n",
    "    plt.plot(x_train[i], label='Input')\n",
    "    plt.plot(predictions[i], label='Prediction')\n",
    "    plt.legend()\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d1b75f63a51ab1e44c10e89cf3b718812d9c5e2447d39cb402b946ba7653bfcd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
